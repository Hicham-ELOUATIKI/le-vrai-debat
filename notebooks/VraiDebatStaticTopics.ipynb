{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original static topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import re, json, numpy as np\n",
    "\n",
    "import nltk\n",
    "from gensim import models, corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load preprocessed data\n",
    "\n",
    "Data is already gathered in a single parquet files with selected columns about opinions (proposals):\n",
    "- title and descriptions\n",
    "- votes (number, positive, mitigate, negative)\n",
    "- arguments (pros, cons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('leVraiDebat-opinions.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['master_tag', 'contributions_id', 'contribution_versions_title',\n",
       "       'contribution_versions_bodyText', 'contributions_votesCount',\n",
       "       'contributions_votesCountOk', 'contributions_votesCountMitige',\n",
       "       'contributions_votesCountNok', 'contributions_argumentsCountFor',\n",
       "       'contributions_argumentsCountAgainst'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selection of opinions\n",
    "\n",
    "For each topic save the 20 best proposals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.set_index('contributions_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['democratie-institutions-referendum-dinitiative-citoyenne',\n",
       "       'economie-finances-travail-compte-public',\n",
       "       'education-jeunesse-enseignement-superieur-recherche-et-innovation',\n",
       "       'europe-affaires-etrangeres-outre-mer', 'justice-police-armee',\n",
       "       'sante-solidarite-handicap', 'sport-culture', 'expression-libre',\n",
       "       'transition-ecologique-solidaire-agriculture-alimentation'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = df.master_tag.unique()\n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_cols = ['contributions_id', 'contribution_versions_title',\n",
    "       'contribution_versions_bodyText', 'contributions_votesCount',\n",
    "       'contributions_votesCountOk', 'contributions_votesCountMitige',\n",
    "       'contributions_votesCountNok', 'contributions_argumentsCountFor',\n",
    "       'contributions_argumentsCountAgainst']\n",
    "for i, topic in enumerate(topics):\n",
    "    main_contributions = df[df.master_tag == topic].sort_values('contributions_votesCountOk', ascending=False)[:20]\n",
    "    main_contributions[saved_cols].to_json('topic_%d_main_contributions.json' % i, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without topic filter => root\n",
    "main_contributions = df.sort_values('contributions_votesCountOk', ascending=False)[:20]\n",
    "main_contributions[saved_cols].to_json('topic_root_main_contributions.json', orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF on each topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup, stemming and tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(nltk.corpus.stopwords.words('french'))\n",
    "stemmer = nltk.stem.snowball.FrenchStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_clean(text, stem_map):\n",
    "    text = re.sub(r\"[,;\\.\\?!:\\-'\\\"/\\(\\)]+\", ' ', text).lower()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # Remove stop words\n",
    "    tokens = filter(lambda w: w not in stop_words, tokens)\n",
    "    # Filter short tokens (length < 3)\n",
    "    tokens = filter(lambda w: len(w) > 2, tokens)\n",
    "    final_tok = []\n",
    "    for tok in tokens:\n",
    "        stem = stemmer.stem(tok)\n",
    "        # Keep the shortest word corresponding to the stem\n",
    "        if stem in stem_map:\n",
    "            if len(tok) < len(stem_map[stem]):\n",
    "                stem_map[stem] = tok\n",
    "        else:\n",
    "            stem_map.update({stem: tok})\n",
    "        final_tok.append(stem)\n",
    "    return final_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4063, 10)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic = topics[0]\n",
    "df_sel = df[df.master_tag == topic]\n",
    "df_sel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem_map = {}\n",
    "tokens = df_sel['contribution_versions_bodyText'].apply(tokenize_clean, args=[stem_map]) # contribution_versions_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4063,), dtype('O'))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.shape, tokens.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words\n",
    "\n",
    "To be submitted to the TF-IDF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(gensim.corpora.dictionary.Dictionary,\n",
       " 12166,\n",
       " pandas.core.series.Series,\n",
       " (4063,))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(tokens)\n",
    "corpus = tokens.apply(dictionary.doc2bow)\n",
    "(type(dictionary), len(dictionary), type(corpus), corpus.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = models.TfidfModel(list(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply TF-IDF on corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4063"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_tfidf = tfidf[corpus]\n",
    "len(corpus_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On doc #0 (limited to 10 words):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.08214360962119363),\n",
       " (1, 0.10157241824588523),\n",
       " (2, 0.08312896364881604),\n",
       " (3, 0.09284609445027353),\n",
       " (4, 0.07289347596852896),\n",
       " (5, 0.16492382410125303),\n",
       " (6, 0.14116672975382005),\n",
       " (7, 0.2578995055662561),\n",
       " (8, 0.19750615073436856),\n",
       " (9, 0.14264491602257198)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_corpus_iter = corpus_tfidf.__iter__()\n",
    "next(tfidf_corpus_iter)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On doc #1 (limited to 10 words):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.027587732813359644),\n",
       " (2, 0.027918661582693897),\n",
       " (12, 0.024347633972334515),\n",
       " (16, 0.09447991585059799),\n",
       " (18, 0.0426333906125081),\n",
       " (20, 0.020882217670552847),\n",
       " (26, 0.02751559840296238),\n",
       " (27, 0.03242901216322029),\n",
       " (37, 0.03293481490743726),\n",
       " (41, 0.06983914172174212)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(tfidf_corpus_iter)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
