{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gensim and Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.WARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import re, json, numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "from gensim import models, corpora\n",
    "\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(nltk.corpus.stopwords.words('french'))\n",
    "stemmer = nltk.stem.snowball.FrenchStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paremeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of topics\n",
    "n_topics = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load preprocessed data\n",
    "\n",
    "Data is already gathered in a single parquet files with selected columns about opinions (proposals):\n",
    "- title and descriptions\n",
    "- votes (number, positive, mitigate, negative)\n",
    "- arguments (pros, cons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('leVraiDebat-opinions.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Take only proposals with more than 10 votes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10766, 10)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sel = df[df.contributions_votesCount >= 10]\n",
    "df_sel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['master_tag', 'contributions_id', 'contribution_versions_title',\n",
       "       'contribution_versions_bodyText', 'contributions_votesCount',\n",
       "       'contributions_votesCountOk', 'contributions_votesCountMitige',\n",
       "       'contributions_votesCountNok', 'contributions_argumentsCountFor',\n",
       "       'contributions_argumentsCountAgainst'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sel.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple bag of word model \n",
    "\n",
    "Tokenize in words and compute word frequencies with Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_words_frequencies(texts):\n",
    "    \"\"\" Remove punctuation, stop words, tokenize and compute frequencies \"\"\"\n",
    "    vect = CountVectorizer(analyzer='word', stop_words=stop_words).fit(texts)\n",
    "    bag_of_words = vect.transform(texts)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    freq = [(word, sum_words[0, idx]) for word, idx in vect.vocabulary_.items()]\n",
    "    return bag_of_words, freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow, word_freqs = compute_words_frequencies(df_sel['contribution_versions_bodyText']) #df_sel['contribution_versions_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('plus', 5965),\n",
       " ('être', 3292),\n",
       " ('tous', 2524),\n",
       " ('faire', 2200),\n",
       " ('tout', 2096),\n",
       " ('france', 2039),\n",
       " ('comme', 1846),\n",
       " ('cette', 1823),\n",
       " ('sans', 1710),\n",
       " ('faut', 1709)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(word_freqs, key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(scipy.sparse.csr.csr_matrix, (10766, 36216))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bow), bow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize, lemmatize and cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_clean(text, stem_map):\n",
    "    text = re.sub(r\"[,;\\.\\?!:\\-'\\\"/\\(\\)]+\", ' ', text).lower()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # Remove stop words\n",
    "    tokens = filter(lambda w: w not in stop_words, tokens)\n",
    "    # Filter short tokens (length < 3)\n",
    "    tokens = filter(lambda w: len(w) > 2, tokens)\n",
    "    final_tok = []\n",
    "    for tok in tokens:\n",
    "        stem = stemmer.stem(tok)\n",
    "        # Keep the shortest word corresponding to the stem\n",
    "        if stem in stem_map:\n",
    "            if len(tok) < len(stem_map[stem]):\n",
    "                stem_map[stem] = tok\n",
    "        else:\n",
    "            stem_map.update({stem: tok})\n",
    "        final_tok.append(stem)\n",
    "    return final_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem_map = {}\n",
    "tokens = df_sel['contribution_versions_bodyText'].apply(tokenize_clean, args=[stem_map]) # contribution_versions_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vot',\n",
       " 'blanc',\n",
       " 'nul',\n",
       " 'donnent',\n",
       " 'droit',\n",
       " 'élus',\n",
       " 'tirag',\n",
       " 'sort',\n",
       " 'list',\n",
       " 'électoral',\n",
       " 'exigent',\n",
       " 'tir',\n",
       " 'sort',\n",
       " 'avoir',\n",
       " 'vot',\n",
       " 'être',\n",
       " 'accord',\n",
       " 'altern',\n",
       " 'femm',\n",
       " 'hommecet',\n",
       " 'modal',\n",
       " 'appliqu',\n",
       " 'tout',\n",
       " 'élect']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(gensim.corpora.dictionary.Dictionary,\n",
       " 21151,\n",
       " pandas.core.series.Series,\n",
       " (10766,))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(tokens)\n",
    "corpus = tokens.apply(dictionary.doc2bow)\n",
    "(type(dictionary), len(dictionary), type(corpus), corpus.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (1, 1),\n",
       " (2, 1),\n",
       " (3, 1),\n",
       " (4, 1),\n",
       " (5, 1),\n",
       " (6, 1),\n",
       " (7, 1),\n",
       " (8, 1),\n",
       " (9, 1),\n",
       " (10, 1),\n",
       " (11, 1),\n",
       " (12, 1),\n",
       " (13, 2),\n",
       " (14, 1),\n",
       " (15, 1),\n",
       " (16, 1),\n",
       " (17, 2),\n",
       " (18, 1),\n",
       " (19, 1),\n",
       " (20, 1),\n",
       " (21, 1)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF\n",
    "\n",
    "- TF-IDF = Term frequency times inverse document frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = models.TfidfModel(list(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.1685044479789146),\n",
       " (1, 0.21631486497120403),\n",
       " (2, 0.15842368976675686),\n",
       " (3, 0.11787815534573075),\n",
       " (4, 0.18490425325506987),\n",
       " (5, 0.2684397000973235),\n",
       " (6, 0.11518919872132773),\n",
       " (7, 0.25537145611030976),\n",
       " (8, 0.17811087419595098),\n",
       " (9, 0.432845753035672),\n",
       " (10, 0.1945145531807684),\n",
       " (11, 0.2523625398498655),\n",
       " (12, 0.23681448721712134),\n",
       " (13, 0.2748202668186016),\n",
       " (14, 0.18536358722256044),\n",
       " (15, 0.2382273838448666),\n",
       " (16, 0.06722287043004423),\n",
       " (17, 0.2494090732486327),\n",
       " (18, 0.15304766510804282),\n",
       " (19, 0.20774001062600111),\n",
       " (20, 0.13586809834482402),\n",
       " (21, 0.07748457223941105)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(corpus_tfidf.__iter__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  LSI\n",
    "\n",
    "- LSI = latent semantic indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=n_topics)  # initialize an LSI transformation\n",
    "corpus_lsi = model_lsi[corpus_tfidf]  # create a double wrapper over the original corpus: bow->tfidf->fold-in-lsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.167*\"plus\" + 0.153*\"retrait\" + 0.142*\"franc\" + 0.136*\"tout\" + 0.130*\"être\" + 0.119*\"tous\" + 0.106*\"citoyen\" + 0.105*\"salair\" + 0.100*\"impôt\" + 0.098*\"vot\"'),\n",
       " (1,\n",
       "  '-0.674*\"retrait\" + -0.258*\"index\" + -0.224*\"csg\" + -0.194*\"inflat\" + 0.178*\"vot\" + -0.153*\"pension\" + -0.145*\"augment\" + -0.129*\"salair\" + 0.104*\"élect\" + 0.095*\"citoyen\"'),\n",
       " (2,\n",
       "  '-0.381*\"vot\" + -0.280*\"retrait\" + -0.253*\"élect\" + -0.179*\"déput\" + 0.179*\"impôt\" + 0.178*\"tax\" + -0.177*\"blanc\" + -0.167*\"mandat\" + 0.142*\"fiscal\" + -0.139*\"assembl\"'),\n",
       " (3,\n",
       "  '0.302*\"impôt\" + 0.274*\"tax\" + 0.254*\"fiscal\" + -0.236*\"enfant\" + 0.209*\"tva\" + 0.199*\"produit\" + 0.189*\"vot\" + 0.135*\"élect\" + 0.130*\"suppress\" + -0.128*\"écol\"'),\n",
       " (4,\n",
       "  '0.411*\"salair\" + -0.358*\"vot\" + 0.198*\"président\" + 0.192*\"déput\" + -0.185*\"blanc\" + 0.181*\"fonctionnair\" + 0.180*\"élus\" + 0.177*\"mandat\" + 0.175*\"avantag\" + -0.165*\"retrait\"'),\n",
       " (5,\n",
       "  '-0.342*\"vot\" + -0.276*\"salair\" + -0.212*\"blanc\" + 0.202*\"franc\" + -0.179*\"enfant\" + 0.168*\"europ\" + 0.162*\"européen\" + -0.156*\"augment\" + 0.150*\"national\" + -0.145*\"élect\"'),\n",
       " (6,\n",
       "  '0.456*\"produit\" + 0.367*\"tva\" + -0.260*\"impôt\" + -0.242*\"fiscal\" + 0.220*\"tax\" + 0.145*\"nécess\" + -0.141*\"revenu\" + -0.137*\"revenus\" + 0.134*\"baiss\" + 0.132*\"lux\"'),\n",
       " (7,\n",
       "  '0.428*\"salair\" + -0.264*\"suppress\" + -0.235*\"enfant\" + 0.212*\"augment\" + 0.186*\"europ\" + -0.167*\"impôt\" + 0.167*\"européen\" + -0.153*\"an\" + -0.152*\"mandat\" + 0.138*\"smic\"')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lsi.print_topics(n_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.1348633016600394),\n",
       " (1, 0.12795015157825454),\n",
       " (2, -0.2349694901724251),\n",
       " (3, 0.07786074507526446),\n",
       " (4, -0.13428832890831666),\n",
       " (5, -0.10558403834894382),\n",
       " (6, -0.01393762408604308),\n",
       " (7, 0.0421819250643696)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(corpus_lsi.__iter__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA\n",
    "\n",
    "- LDA = Latent Dirichlet Allocation\n",
    "\n",
    "It is an alternative to LSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training parameters.\n",
    "num_topics = 10\n",
    "chunksize = 2000\n",
    "passes = 10\n",
    "iterations = 400\n",
    "eval_every = 10  # None # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "model_lda = models.LdaModel(\n",
    "    corpus=corpus_tfidf,\n",
    "    # Make a index to word dictionary.\n",
    "    id2word=dictionary.id2token,\n",
    "    chunksize=2000,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=n_topics,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average topic coherence: 0.0000.\n",
      "[([(0.0010049989, 'loup'),\n",
      "   (0.00073100405, 'suprim'),\n",
      "   (0.0007097097, 'polut'),\n",
      "   (0.000648844, 'accetuent'),\n",
      "   (0.0006225631, 'chéqui'),\n",
      "   (0.0005979181, 'gafam'),\n",
      "   (0.00048847497, 'assang'),\n",
      "   (0.00046044556, 'détentric'),\n",
      "   (0.00044841712, 'vehicul'),\n",
      "   (0.00042725384, 'exhorbit'),\n",
      "   (0.0004053292, 'perso'),\n",
      "   (0.0003859664, 'financebien'),\n",
      "   (0.0003859664, 'calculet'),\n",
      "   (0.00036922356, 'déport'),\n",
      "   (0.00033569333, 'proportionnal'),\n",
      "   (0.00030790886, 'trap'),\n",
      "   (0.0001953721, 'dom'),\n",
      "   (0.00016925643, 'tom'),\n",
      "   (0.00016423094, 'publicitair'),\n",
      "   (0.00013948757, 'golf')],\n",
      "  0.0),\n",
      " ([(0.008044101, 'radar'),\n",
      "   (0.002212101, 'dépendr'),\n",
      "   (0.0017695649, 'suspendr'),\n",
      "   (0.0014891364, 'poul'),\n",
      "   (0.0010300595, 'pain'),\n",
      "   (0.00081653113, 'different'),\n",
      "   (0.0007247895, 'cliniqu'),\n",
      "   (0.0006720397, 'epargn'),\n",
      "   (0.00054665306, 'monetair'),\n",
      "   (0.00046617186, 'ras'),\n",
      "   (0.00043776163, 'reindex'),\n",
      "   (0.0004236827, 'deductibl'),\n",
      "   (0.00040278866, 'hommag'),\n",
      "   (0.00038062717, 'donat'),\n",
      "   (0.0003693305, 'resoudr'),\n",
      "   (0.00036347416, '6000€'),\n",
      "   (0.00036047326, 'bol'),\n",
      "   (0.00035604066, 'ice'),\n",
      "   (0.00032396565, 'cabin'),\n",
      "   (0.00029984672, 'agreg')],\n",
      "  0.0),\n",
      " ([(0.00100469, 'tiron'),\n",
      "   (0.00090212625, 'aix'),\n",
      "   (0.0008984106, 'a9hicule_'),\n",
      "   (0.0008984106, 'a0_air_comprim'),\n",
      "   (0.00088173745, 'mayott'),\n",
      "   (0.0008021765, 'redinamis'),\n",
      "   (0.00069503055, 'alsac'),\n",
      "   (0.0005675315, 'mosel'),\n",
      "   (0.0005221006, 'md'),\n",
      "   (0.00032728145, 'independ'),\n",
      "   (0.00024325441, 'concordat'),\n",
      "   (0.00023682721, 'moulin'),\n",
      "   (0.0002170996, '+35'),\n",
      "   (0.00020751251, '+100'),\n",
      "   (0.00013321718, 'réindex'),\n",
      "   (0.00012776192, 'navig'),\n",
      "   (0.00011721216, 'réélus'),\n",
      "   (0.00011505199, 'chapel'),\n",
      "   (0.00010810314, 'investissementmoin'),\n",
      "   (0.00010810314, 'mdssuppress')],\n",
      "  0.0),\n",
      " ([(0.004324572, 'plus'),\n",
      "   (0.0035023217, 'tout'),\n",
      "   (0.0033862928, 'franc'),\n",
      "   (0.002970461, 'retrait'),\n",
      "   (0.0029483605, 'tous'),\n",
      "   (0.002863727, 'être'),\n",
      "   (0.0028058398, 'tax'),\n",
      "   (0.0027330893, 'produit'),\n",
      "   (0.002468451, 'fair'),\n",
      "   (0.002363503, 'faut'),\n",
      "   (0.0021315995, 'autr'),\n",
      "   (0.0021265757, 'transport'),\n",
      "   (0.0021052782, 'pay'),\n",
      "   (0.0021017331, 'cet'),\n",
      "   (0.0020670807, 'comm'),\n",
      "   (0.0020583323, 'person'),\n",
      "   (0.0020539179, 'doit'),\n",
      "   (0.0020504782, 'cel'),\n",
      "   (0.0019777387, 'non'),\n",
      "   (0.0019724471, 'san')],\n",
      "  0.0),\n",
      " ([(0.0082627265, 'consign'),\n",
      "   (0.002738806, 'honorair'),\n",
      "   (0.0024489518, 'notair'),\n",
      "   (0.0020834245, 'veuv'),\n",
      "   (0.0016483446, 'veuf'),\n",
      "   (0.00087189523, 'execut'),\n",
      "   (0.0007341025, 'ass'),\n",
      "   (0.0005501052, 'redevien'),\n",
      "   (0.0005206495, 'assemble'),\n",
      "   (0.00042957207, 'tig'),\n",
      "   (0.00041442944, 'monsanto'),\n",
      "   (0.00040752458, 'preferent'),\n",
      "   (0.00037301896, 'epous'),\n",
      "   (0.00032305787, 'sionist'),\n",
      "   (0.00026162073, 'echapp'),\n",
      "   (0.00024308084, 'autodétermin'),\n",
      "   (0.00024275578, 'equilibr'),\n",
      "   (0.00022454277, 'revoi'),\n",
      "   (0.00021361666, 'musulman'),\n",
      "   (0.00021016056, 'cyclist')],\n",
      "  0.0),\n",
      " ([(0.01169924, 'véhicul'),\n",
      "   (0.0071597747, 'aliment'),\n",
      "   (0.006692157, 'éolien'),\n",
      "   (0.0062716147, 'carbur'),\n",
      "   (0.006265524, 'inflat'),\n",
      "   (0.005485267, 'routi'),\n",
      "   (0.0049685077, 'agricol'),\n",
      "   (0.004508795, 'industr'),\n",
      "   (0.0044594943, 'solair'),\n",
      "   (0.00406628, 'récuper'),\n",
      "   (0.0040091197, 'producteur'),\n",
      "   (0.0037987435, 'émiss'),\n",
      "   (0.0037065016, 'adapt'),\n",
      "   (0.003677548, 'secteur'),\n",
      "   (0.0036752664, 'panneau'),\n",
      "   (0.003672976, 'coup'),\n",
      "   (0.0035541458, 'distribu'),\n",
      "   (0.0034816838, 'lobb'),\n",
      "   (0.0032759605, 'biodivers'),\n",
      "   (0.0030865418, 'mang')],\n",
      "  0.0),\n",
      " ([(0.006929166, 'camion'),\n",
      "   (0.003957922, 'étudi'),\n",
      "   (0.0038466568, 'fronti'),\n",
      "   (0.0038412805, 'loyer'),\n",
      "   (0.0033456578, 'villag'),\n",
      "   (0.003222595, 'recyclag'),\n",
      "   (0.0031565363, 'detr'),\n",
      "   (0.003099741, 'support'),\n",
      "   (0.0030610787, 'global'),\n",
      "   (0.0030413172, 'pur'),\n",
      "   (0.0029281282, 'arrêton'),\n",
      "   (0.0028975555, 'indic'),\n",
      "   (0.0028322935, 'trafic'),\n",
      "   (0.0026993367, 'aménag'),\n",
      "   (0.002647261, 'control'),\n",
      "   (0.0026145547, 'parad'),\n",
      "   (0.0025995583, 'licenci'),\n",
      "   (0.002559647, 'redev'),\n",
      "   (0.0023974036, 'illégal'),\n",
      "   (0.0023968716, 'marg')],\n",
      "  0.0),\n",
      " ([(0.00055353605, 'tueur'),\n",
      "   (0.0005031508, 'smig'),\n",
      "   (0.00039131482, 'clart'),\n",
      "   (0.00026504896, 'citoyenséduqu'),\n",
      "   (0.00026504896, 'défendrecollabor'),\n",
      "   (0.00024325191, 'fax'),\n",
      "   (9.911475e-05, 'syndiqu'),\n",
      "   (5.095989e-05, 'violeur'),\n",
      "   (5.056831e-05, 'elev'),\n",
      "   (4.9722526e-05, 'constitutionnalis'),\n",
      "   (4.903235e-05, 'spot'),\n",
      "   (4.8360795e-05, 'v=fsecarselv0débat'),\n",
      "   (4.8347818e-05, 'stérilis'),\n",
      "   (4.829287e-05, 'reduir'),\n",
      "   (4.8276535e-05, 'castrat'),\n",
      "   (4.801737e-05, 'pat'),\n",
      "   (4.7953614e-05, 'aquarius'),\n",
      "   (4.772277e-05, 'gayssot'),\n",
      "   (4.7710895e-05, 'navir'),\n",
      "   (4.7684498e-05, 'kurd')],\n",
      "  0.0)]\n"
     ]
    }
   ],
   "source": [
    "top_topics = model_lda.top_topics(corpus_lsi) #, num_words=20)\n",
    "\n",
    "# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
    "avg_topic_coherence = sum([t[1] for t in top_topics]) / num_topics\n",
    "print('Average topic coherence: %.4f.' % avg_topic_coherence)\n",
    "\n",
    "from pprint import pprint\n",
    "pprint(top_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = np.array(list(map(lambda t: list(map(lambda tt: tt[0], t[0])), top_topics)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform stems in closest shortest word and prepare for JSON output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_topics_reworked = []\n",
    "font_scale = 50 / all_scores.max()\n",
    "font_size_min = 9\n",
    "font_size_max = 36\n",
    "max_words = 10\n",
    "for topic in top_topics:\n",
    "    topic_reworked = [{'size': min(max(word_duplet[0] * font_scale, font_size_min), font_size_max), 'text' : stem_map[word_duplet[1]]} for word_duplet in topic[0][:max_words]]\n",
    "    top_topics_reworked.append(topic_reworked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'size': 9, 'text': 'loups'},\n",
      "  {'size': 9, 'text': 'suprimés'},\n",
      "  {'size': 9, 'text': 'polution'},\n",
      "  {'size': 9, 'text': 'accetuent'},\n",
      "  {'size': 9, 'text': 'chéquier'},\n",
      "  {'size': 9, 'text': 'gafam'},\n",
      "  {'size': 9, 'text': 'assange'},\n",
      "  {'size': 9, 'text': 'détentrice'},\n",
      "  {'size': 9, 'text': 'vehicule'},\n",
      "  {'size': 9, 'text': 'exhorbitant'}],\n",
      " [{'size': 34.3787352342942, 'text': 'radar'},\n",
      "  {'size': 9.454036960624705, 'text': 'dépendre'},\n",
      "  {'size': 9, 'text': 'suspendre'},\n",
      "  {'size': 9, 'text': 'poule'},\n",
      "  {'size': 9, 'text': 'pain'},\n",
      "  {'size': 9, 'text': 'different'},\n",
      "  {'size': 9, 'text': 'clinique'},\n",
      "  {'size': 9, 'text': 'epargne'},\n",
      "  {'size': 9, 'text': 'monetaire'},\n",
      "  {'size': 9, 'text': 'ras'}],\n",
      " [{'size': 9, 'text': 'tirons'},\n",
      "  {'size': 9, 'text': 'aix'},\n",
      "  {'size': 9, 'text': 'a9hicule_'},\n",
      "  {'size': 9, 'text': 'a0_air_comprim'},\n",
      "  {'size': 9, 'text': 'mayotte'},\n",
      "  {'size': 9, 'text': 'redinamiser'},\n",
      "  {'size': 9, 'text': 'alsace'},\n",
      "  {'size': 9, 'text': 'moselle'},\n",
      "  {'size': 9, 'text': 'mds'},\n",
      "  {'size': 9, 'text': 'independant'}],\n",
      " [{'size': 18.482278605660596, 'text': 'plus'},\n",
      "  {'size': 14.968159235941073, 'text': 'tout'},\n",
      "  {'size': 14.472277342323013, 'text': 'franc'},\n",
      "  {'size': 12.695102867282765, 'text': 'retraite'},\n",
      "  {'size': 12.600650073559365, 'text': 'tous'},\n",
      "  {'size': 12.238945059780866, 'text': 'être'},\n",
      "  {'size': 11.991547419778264, 'text': 'tax'},\n",
      "  {'size': 11.680627661457052, 'text': 'produit'},\n",
      "  {'size': 10.549621106191765, 'text': 'faire'},\n",
      "  {'size': 10.101096460799956, 'text': 'faut'}],\n",
      " [{'size': 35.31309159245255, 'text': 'consigne'},\n",
      "  {'size': 11.705059551600336, 'text': 'honoraire'},\n",
      "  {'size': 10.466286200651922, 'text': 'notaire'},\n",
      "  {'size': 9, 'text': 'veuve'},\n",
      "  {'size': 9, 'text': 'veuf'},\n",
      "  {'size': 9, 'text': 'execute'},\n",
      "  {'size': 9, 'text': 'ass'},\n",
      "  {'size': 9, 'text': 'redevienne'},\n",
      "  {'size': 9, 'text': 'assemblee'},\n",
      "  {'size': 9, 'text': 'tig'}],\n",
      " [{'size': 36, 'text': 'véhicule'},\n",
      "  {'size': 30.599315966780036, 'text': 'aliment'},\n",
      "  {'size': 28.60082058831092, 'text': 'éolien'},\n",
      "  {'size': 26.803513909410498, 'text': 'carburant'},\n",
      "  {'size': 26.77748294593767, 'text': 'inflation'},\n",
      "  {'size': 23.442834929540872, 'text': 'routier'},\n",
      "  {'size': 21.23431863316267, 'text': 'agricole'},\n",
      "  {'size': 19.269607783433212, 'text': 'industrie'},\n",
      "  {'size': 19.058906239414974, 'text': 'solaire'},\n",
      "  {'size': 17.378394602818048, 'text': 'récupère'}],\n",
      " [{'size': 29.613745479110236, 'text': 'camion'},\n",
      "  {'size': 16.91529620012414, 'text': 'étudié'},\n",
      "  {'size': 16.439772390668562, 'text': 'frontière'},\n",
      "  {'size': 16.41679528908022, 'text': 'loyers'},\n",
      "  {'size': 14.29861220734371, 'text': 'village'},\n",
      "  {'size': 13.772668332170698, 'text': 'recyclage'},\n",
      "  {'size': 13.49034780631021, 'text': 'détriment'},\n",
      "  {'size': 13.247617032465389, 'text': 'support'},\n",
      "  {'size': 13.082383103659835, 'text': 'global'},\n",
      "  {'size': 12.99792675714775, 'text': 'pur'}],\n",
      " [{'size': 9, 'text': 'tueur'},\n",
      "  {'size': 9, 'text': 'smig'},\n",
      "  {'size': 9, 'text': 'clarté'},\n",
      "  {'size': 9, 'text': 'citoyenséduquer'},\n",
      "  {'size': 9, 'text': 'défendrecollaboration'},\n",
      "  {'size': 9, 'text': 'fax'},\n",
      "  {'size': 9, 'text': 'syndiqué'},\n",
      "  {'size': 9, 'text': 'violeur'},\n",
      "  {'size': 9, 'text': 'eleve'},\n",
      "  {'size': 9, 'text': 'constitutionnaliser'}]]\n"
     ]
    }
   ],
   "source": [
    "pprint(top_topics_reworked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('topics.json', 'w') as f:\n",
    "    json.dump(top_topics_reworked, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_lda = model_lda[corpus] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 0.9065392), (5, 0.07001161), (6, 0.013914187)] Tirage au sort pour les Votes blancs\n",
      "[(3, 0.9277998), (5, 0.031275228), (6, 0.0317344)] PAS D'ANONYMAT DANS L'ABSTENTION\n",
      "[(3, 0.9316617), (5, 0.029754499), (6, 0.037294496)] Pic-Ric --- Action pour une organisation du mouvement par vote (mise en place immédiat du 1er RIC) et création d'un espace conviviale et pacifiste\n",
      "[(3, 0.9299177), (5, 0.040551785), (6, 0.017493946)] Organiser des Référendums pour toutes les questions importantes (idem nos voisins suisses) et que le résultat soit pris en compte et respecté.\n",
      "[(3, 0.9264364), (5, 0.04256608), (6, 0.018362926)] Avoir une formation à la démocratie à l'école (Maternelle à l'Université) dans la vie associative et la vie courante\n",
      "[(3, 0.92259043), (5, 0.044791408), (6, 0.019322945)] Avant chaque vote, le député organise un débat local sur la loi\n",
      "[(3, 0.9245579), (5, 0.043653093), (6, 0.01883184)] \"Sanctionner financièrement le non vote à tous les scrutins,   ( votes rendus obligatoires)\"\n",
      "[(3, 0.932885), (5, 0.038888447), (6, 0.016754879)] Le RIC est ridicule\n",
      "[(3, 0.9022309), (4, 0.027211627), (5, 0.04261676), (6, 0.018384155)] Nationalité\n",
      "[(3, 0.9485936), (5, 0.035221204)] Pour une Assemblée Constituante universelle !\n"
     ]
    }
   ],
   "source": [
    "for doc, as_text in zip(corpus_lda, df_sel['contribution_versions_title'][:10]):\n",
    "    print(doc, as_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References and inspirations\n",
    "\n",
    "- https://radimrehurek.com/gensim/auto_examples/core/run_topics_and_transformations.html#sphx-glr-auto-examples-core-run-topics-and-transformations-py\n",
    "- https://radimrehurek.com/gensim/auto_examples/tutorials/run_lda.html#sphx-glr-auto-examples-tutorials-run-lda-py\n",
    "- https://towardsdatascience.com/topic-modeling-with-latent-dirichlet-allocation-by-example-3b22cd10c835\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_width = [len(x) for x in corpus_lda]\n",
    "np.max(corpus_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_for_topics = [sum([list(map(lambda y: (t, y[0][i][1], y[1], y[2]), filter(lambda x: len(x[0]) > i and x[0][i][0] == t, zip(corpus_lda, df_sel['contribution_versions_title'], df_sel['contribution_versions_bodyText'])))) for i in range(4)], []) for t in range(n_topics)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_topics = pd.DataFrame(sum(docs_for_topics, []), columns=['topic', 'score', 'title', 'body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>score</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.052258</td>\n",
       "      <td>salaires hauts fonctionaires (exemple:chantal ...</td>\n",
       "      <td>revoir les salaires exhorbitants des hauts fon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.031012</td>\n",
       "      <td>introduction de votes proportionnels aux légis...</td>\n",
       "      <td>Introduire une proportionnalité aux élections ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.033588</td>\n",
       "      <td>STOP à : MOI JE VEUX UNE AIDE POUR...</td>\n",
       "      <td>On remarque l’énorme décalage entre les demand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.031979</td>\n",
       "      <td>Proportionnel</td>\n",
       "      <td>Mettre une dose de proportionnalité de 20%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.010713</td>\n",
       "      <td>Finir le travail du CNR</td>\n",
       "      <td>Appel des Résistants aux jeunes générations du...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topic     score                                              title  \\\n",
       "0      0  0.052258  salaires hauts fonctionaires (exemple:chantal ...   \n",
       "1      0  0.031012  introduction de votes proportionnels aux légis...   \n",
       "2      0  0.033588              STOP à : MOI JE VEUX UNE AIDE POUR...   \n",
       "3      0  0.031979                                      Proportionnel   \n",
       "4      0  0.010713                            Finir le travail du CNR   \n",
       "\n",
       "                                                body  \n",
       "0  revoir les salaires exhorbitants des hauts fon...  \n",
       "1  Introduire une proportionnalité aux élections ...  \n",
       "2  On remarque l’énorme décalage entre les demand...  \n",
       "3         Mettre une dose de proportionnalité de 20%  \n",
       "4  Appel des Résistants aux jeunes générations du...  "
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for_topics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>score</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>2</td>\n",
       "      <td>0.191916</td>\n",
       "      <td>Suppression de la CSG et redistribution solidaire</td>\n",
       "      <td>Suppression de la CSG +100 mdsSuppression des ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>2</td>\n",
       "      <td>0.187459</td>\n",
       "      <td>Suppression des niches fiscales et De la CSG</td>\n",
       "      <td>Suppression de la CSG +100 mdsSuppression des ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>2</td>\n",
       "      <td>0.070888</td>\n",
       "      <td>Concordats</td>\n",
       "      <td>Abrogation des Concordats d'Alsace-Moselle et ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>2</td>\n",
       "      <td>0.063484</td>\n",
       "      <td>Concordats</td>\n",
       "      <td>Abrogation des concordats d'Alsace-Moselle et ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>2</td>\n",
       "      <td>0.060509</td>\n",
       "      <td>« L’Etat chez lui, L’Eglise chez elle »  disai...</td>\n",
       "      <td>Abrogation du Statut clérical d’exception d’Al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>2</td>\n",
       "      <td>0.057602</td>\n",
       "      <td>Developper la voiture a air comprimé</td>\n",
       "      <td>https://fr.wikipedia.org/wiki/V%C3%A9hicule_%C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>2</td>\n",
       "      <td>0.047641</td>\n",
       "      <td>Etendre le respect du principe de laïcité à to...</td>\n",
       "      <td>Il s'agit d'abroger le régime concordataire qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>2</td>\n",
       "      <td>0.043780</td>\n",
       "      <td>Ajout de points de TVA sur les produits de lux...</td>\n",
       "      <td>https://www.toute-la-franchise.com/vie-de-la-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>2</td>\n",
       "      <td>0.038703</td>\n",
       "      <td>Référendum</td>\n",
       "      <td>Un référendum avait  été organisé à Mayotte po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>2</td>\n",
       "      <td>0.038333</td>\n",
       "      <td>MAYOTTE ET LES COMMORES</td>\n",
       "      <td>Le gouvernement de Mayotte refuse depuis 6 moi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     topic     score                                              title  \\\n",
       "190      2  0.191916  Suppression de la CSG et redistribution solidaire   \n",
       "177      2  0.187459       Suppression des niches fiscales et De la CSG   \n",
       "176      2  0.070888                                         Concordats   \n",
       "175      2  0.063484                                         Concordats   \n",
       "187      2  0.060509  « L’Etat chez lui, L’Eglise chez elle »  disai...   \n",
       "192      2  0.057602               Developper la voiture a air comprimé   \n",
       "184      2  0.047641  Etendre le respect du principe de laïcité à to...   \n",
       "173      2  0.043780  Ajout de points de TVA sur les produits de lux...   \n",
       "186      2  0.038703                                         Référendum   \n",
       "178      2  0.038333                            MAYOTTE ET LES COMMORES   \n",
       "\n",
       "                                                  body  \n",
       "190  Suppression de la CSG +100 mdsSuppression des ...  \n",
       "177  Suppression de la CSG +100 mdsSuppression des ...  \n",
       "176  Abrogation des Concordats d'Alsace-Moselle et ...  \n",
       "175  Abrogation des concordats d'Alsace-Moselle et ...  \n",
       "187  Abrogation du Statut clérical d’exception d’Al...  \n",
       "192  https://fr.wikipedia.org/wiki/V%C3%A9hicule_%C...  \n",
       "184  Il s'agit d'abroger le régime concordataire qu...  \n",
       "173  https://www.toute-la-franchise.com/vie-de-la-f...  \n",
       "186  Un référendum avait  été organisé à Mayotte po...  \n",
       "178  Le gouvernement de Mayotte refuse depuis 6 moi...  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for_topics[df_for_topics.topic == 2].sort_values('score', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
